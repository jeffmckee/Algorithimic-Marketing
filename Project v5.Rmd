---
title: "Project"
author: "Warren Speth and Jeff"
date: "March 3, 2019"
output: html_document
---
#making changes
```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r}
library(caret)
library(data.table)
library(glmnet)
library(rpart)
library(rpart.plot)
library(randomForest)
library(xgboost)
library(gbm)

log_prob <- function(pred){
  1/(1+exp(-pred))
}
```


```{r}
df <- read.csv("bank_additional_full.csv")

levels(df$job)[2] <- "bluecollar"
levels(df$job)[7] <- "selfemployed"


df <- as.data.table(model.matrix(~.-1,df))
# colnames(df)[colnames(df)=="ytrue"] <- "outcome"
df$Class <- ifelse(df$ytrue==1,TRUE,FALSE)
```

```{r}
# 
# summary(df)
# str(df)
# table(df$campaign)
# 
# barplot(table(df$Class,df$campaign)[2,1:15]/(table(df$Class,df$campaign)[1,1:15]+table(df$Class,df$campaign)[2,1:15]))
```


```{r}
df[,ID := .I]

#split into test and train
set.seed(99)
training_size <- floor(0.80 * nrow(df))
train_ind <- sample(seq_len(nrow(df)), size = training_size)

df_train <- df[train_ind, ]

df_test <- df[-train_ind, ]
df_test[,campaign2 := ifelse(campaign == 2, 1,0)]
df_test[,campaign3 := ifelse(campaign == 3, 1,0)]
df_test[,campaign4 := ifelse(campaign == 4, 1,0)]
df_test[,campaign5 := ifelse(campaign == 5, 1,0)]
df_test$campaign[df_test$campaign>5]<-5


# Work on training data
full_df <- df_train[rep(1:.N,campaign)][,campaign_no:=1:.N,by=ID]
full_df[campaign != campaign_no,'Class'] <- FALSE
full_df[,campaign2 := ifelse(campaign_no == 2, 1,0)]
full_df[,campaign3 := ifelse(campaign_no == 3, 1,0)]
full_df[,campaign4 := ifelse(campaign_no == 4, 1,0)]
full_df[,campaign5 := ifelse(campaign_no == 5, 1,0)]
model_df<-full_df[campaign_no<=5,c(56,1:30,47:49, 59:62)]
x_matrix <- model.matrix(Class~.+.*campaign2+.*campaign3+.*campaign4+.*campaign5-1,data=model_df)

#work on testing data


<<<<<<< HEAD
=======
df_test[,outcome  :=  ifelse(Class       =="TRUE",1,0)]
df_test[,campaign2 := ifelse(campaign == 2, 1,0)]
df_test[,campaign3 := ifelse(campaign == 3, 1,0)]
df_test[,campaign4 := ifelse(campaign == 4, 1,0)]
df_test[,campaign5 := ifelse(campaign == 5, 1,0)]
df_test$campaign[df_test$campaign>5]<-5
>>>>>>> a95208ba95f793132812f6a5217672fa3c3e14ee
```

```{r}
#cv_enet <- cv.glmnet(x=x_matrix, y=model_df$Class, family="binomial")
best_lambda <- 0.0007920194
enet <- glmnet(x=x_matrix, y=model_df$Class, family="binomial")

test_reg <- glm(Class~.+.*campaign2+.*campaign3+.*campaign4+.*campaign5,data=model_df,family="binomial",control = list(maxit = 50))
```


```{r}
#ASSUMPTIONS:

          wage <-12 #Estimate of hourly wage 
          fail_time <-mean(df$duration[df$Class=="FALSE"]) / 3600
          success_time <-mean(df$duration[df$Class=="TRUE"]) / 3600
          Inter_call_time <-1/60
          fail_cost<-wage*(fail_time+Inter_call_time)
          success_cost <-wage*(success_time+Inter_call_time)
          
  #Output: [cost of failure], [cost of success/signup]
#Profit from successful customer: According to a paper, CD rates in the Netherlands average ~60% of Euribor rates (https://onlinelibrary.wiley.com/doi/full/10.1111/irfi.12143)
          Market_rate <-.025 
          CD_rate <-Market_rate*.6
          Balance<-10000 #(simply assumed)
          Term <- .25 #(.25 years, assumed based on rate)
          Revenue <- Balance*Term*(Market_rate-CD_rate)  #(roughly a function of not having to borrow this money at market rates, flat curve assumed)
          Success_profit <-Revenue - success_cost

```

```{r}
#Generate estimates of cost per call, benefit (revenue/profit) of time deposit product for bank

        #Cost- Relevant inputs: hourly wage, average call information (separate averages for failures and successes          b/c they have drastically different lengths)

Compute_Sample_Profitability<-function(obs){
          sample_person <-df_test[obs]
          
          
    #from regression coefficients + person's info: Simple prediction of success likelihood on the nth call "prob(n)" (conditional on failures for all previous calls)
log_prob <- function(logodds){
  1/(1+exp(-logodds))
}

#Loops through prediction turning on campaigns to calculate probabilities of success on calls 1:5
prob <-rep(NA,5)
    sample_person$campaign2<-0
    sample_person$campaign3<-0
    sample_person$campaign4<-0
    sample_person$campaign5<-0
prob[1] <-log_prob(predict(test_reg,sample_person))
    sample_person$campaign2<-1
prob[2] <-log_prob(predict(test_reg,sample_person))
    sample_person$campaign2<-0
    sample_person$campaign3<-1
prob[3] <-log_prob(predict(test_reg,sample_person))
    sample_person$campaign3<-0
    sample_person$campaign4<-1
prob[4] <-log_prob(predict(test_reg,sample_person))
    sample_person$campaign4<-0
    sample_person$campaign5<-1
prob[5] <-log_prob(predict(test_reg,sample_person))
    sample_person$campaign5<-0


    #For Calls 1 through N, compute likelihood of success by the nth call: p_sub(n)
        
p_sub<-rep(NA,5)
  p_sub[1]<-prob[1]
  for (i in 2:5) {
    p_sub[i] <-p_sub[i-1]+prob[i]*(1-p_sub[i-1])
  }

  
  #For calls 1 through N, compute lift of call n: lift(n)= p_sub(n) - p_sub(n-1) (this represents unconditional probability of success on call n)
lift<-rep(NA,5)
  lift[1]<-p_sub[1]
  for (i in 2:5) {
    lift[i] <-p_sub[i]-p_sub[i-1]
  }
  
#Compute number of calls to target for a given customer (N.B.: As long as probability of success is declining monotonically, as soon as the nth call is not profitable, the (n+1)th call will also not be profitable.) 
  #Test: Identify whether the nth call (if made) would be profitable. THis is simple:
   #Profit(n|All calls prior="no")=[Profit of Success]*p_sub(n) -[Cost of Failure]*(1-p_sub(n)) 
  Profit <- rep(NA,5)
  for (i in 1:5){
    Profit[i] <- Success_profit*prob[i]-fail_cost*(1-prob[i])
  }
  #Decision: for the first unprofitable call "A," choose  A-1 as the target number of calls.
  Calls_to_make<-0
  Calls_to_make <-NROW(Profit[Profit>0])
  #based out this decision (target customer with A-1 calls), also compute 
    #(1) the expected number of calls with that rule(this is not simply A-1 b/c customer may sign up earlier), and
Expected_calls <- 0
if(Calls_to_make<=1) {
  Expected_calls<-Calls_to_make
}  else {
    for (i in 1:(Calls_to_make-1)){
      Expected_calls<-Expected_calls+i*lift[i]
    }
    Expected_calls<-Expected_calls+Calls_to_make*(1-p_sub[Calls_to_make-1])
  }

    #(2) the expected profit from this strategy (weighted average of profitabilities forscenarios given this targeting plan, weighting each scenario by lift(n) and then adding together)
  
  
  Expected_profit <- 0
  if (Calls_to_make>0){
    for (i in 1:Calls_to_make){
      Expected_profit <-Expected_profit+lift[i]*(Success_profit-fail_cost*(i-1))
    }
    Expected_profit <-Expected_profit-fail_cost*Calls_to_make*(1-p_sub[Calls_to_make])
  } 

  Metrics <-c("Euribor","Max Calls","Expected Calls", "Profit")
  values<-c(Market_rate,Calls_to_make,Expected_calls,Expected_profit)
  results <-data.frame(Metrics,values)
#  print(results)
  
  return(Calls_to_make)

}

```

```{r}
#Generate estimates of cost per call, benefit (revenue/profit) of time deposit product for bank

        #Cost- Relevant inputs: hourly wage, average call information (separate averages for failures and successes          b/c they have drastically different lengths)

Compute_Sample_Profitability_LASSO<-function(obs){
          sample_person <-df_test[obs]
          
#Loops through prediction turning on campaigns to calculate probabilities of success on calls 1:5
prob <-rep(NA,5)
    sample_person$campaign2<-0
    sample_person$campaign3<-0
    sample_person$campaign4<-0
    sample_person$campaign5<-0
    lasso_test<-sample_person[,c(56,1:30,47:49, 58:61)]
    test_matrix <- model.matrix(Class~.+.*campaign2+.*campaign3+.*campaign4+.*campaign5-1,data=lasso_test)
prob[1] <-log_prob(predict(enet,newx=test_matrix,s=best_lambda))
    sample_person$campaign2<-1
    lasso_test<-sample_person[,c(56,1:30,47:49, 58:61)]
    test_matrix <- model.matrix(Class~.+.*campaign2+.*campaign3+.*campaign4+.*campaign5-1,data=lasso_test)
prob[2] <-log_prob(predict(enet,newx=test_matrix,s=best_lambda))
    sample_person$campaign2<-0
    sample_person$campaign3<-1
    lasso_test<-sample_person[,c(56,1:30,47:49, 58:61)]
    test_matrix <- model.matrix(Class~.+.*campaign2+.*campaign3+.*campaign4+.*campaign5-1,data=lasso_test)
prob[3] <-log_prob(predict(enet,newx=test_matrix,s=best_lambda))
    sample_person$campaign3<-0
    sample_person$campaign4<-1
    lasso_test<-sample_person[,c(56,1:30,47:49, 58:61)]
    test_matrix <- model.matrix(Class~.+.*campaign2+.*campaign3+.*campaign4+.*campaign5-1,data=lasso_test)
prob[4] <-log_prob(predict(enet,newx=test_matrix,s=best_lambda))
    sample_person$campaign4<-0
    sample_person$campaign5<-1
    lasso_test<-sample_person[,c(56,1:30,47:49, 58:61)]
    test_matrix <- model.matrix(Class~.+.*campaign2+.*campaign3+.*campaign4+.*campaign5-1,data=lasso_test)
prob[5] <-log_prob(predict(enet,newx=test_matrix,s=best_lambda))


    #For Calls 1 through N, compute likelihood of success by the nth call: p_sub(n)
        
p_sub<-rep(NA,5)
  p_sub[1]<-prob[1]
  for (i in 2:5) {
    p_sub[i] <-p_sub[i-1]+prob[i]*(1-p_sub[i-1])
  }

  
  #For calls 1 through N, compute lift of call n: lift(n)= p_sub(n) - p_sub(n-1) (this represents unconditional probability of success on call n)
lift<-rep(NA,5)
  lift[1]<-p_sub[1]
  for (i in 2:5) {
    lift[i] <-p_sub[i]-p_sub[i-1]
  }
  
#Compute number of calls to target for a given customer (N.B.: As long as probability of success is declining monotonically, as soon as the nth call is not profitable, the (n+1)th call will also not be profitable.) 
  #Test: Identify whether the nth call (if made) would be profitable. THis is simple:
   #Profit(n|All calls prior="no")=[Profit of Success]*p_sub(n) -[Cost of Failure]*(1-p_sub(n)) 
  Profit <- rep(NA,5)
  for (i in 1:5){
    Profit[i] <- Success_profit*prob[i]-fail_cost*(1-prob[i])
  }
  #Decision: for the first unprofitable call "A," choose  A-1 as the target number of calls.
  Calls_to_make<-0
  Calls_to_make <-NROW(Profit[Profit>0])
  #based out this decision (target customer with A-1 calls), also compute 
    #(1) the expected number of calls with that rule(this is not simply A-1 b/c customer may sign up earlier), and
Expected_calls <- 0
if(Calls_to_make<=1) {
  Expected_calls<-Calls_to_make
}  else {
    for (i in 1:(Calls_to_make-1)){
      Expected_calls<-Expected_calls+i*lift[i]
    }
    Expected_calls<-Expected_calls+Calls_to_make*(1-p_sub[Calls_to_make-1])
  }

    #(2) the expected profit from this strategy (weighted average of profitabilities forscenarios given this targeting plan, weighting each scenario by lift(n) and then adding together)
  
  
  Expected_profit <- 0
  if (Calls_to_make>0){
    for (i in 1:Calls_to_make){
      Expected_profit <-Expected_profit+lift[i]*(Success_profit-fail_cost*(i-1))
    }
    Expected_profit <-Expected_profit-fail_cost*Calls_to_make*(1-p_sub[Calls_to_make])
  } 

  Metrics <-c("Euribor","Max Calls","Expected Calls", "Profit")
  values<-c(Market_rate,Calls_to_make,Expected_calls,Expected_profit)
  results <-data.frame(Metrics,values)
#  print(results)
  
  return(Calls_to_make)

}

```


```{r}
#Predict decisions (max calls to make) for test dataset
df_test<-df_test[df_test$campaign<=5]
df_test$Max_calls<-0
for (x in 1:nrow(df_test)) {
  df_test$Max_calls[x] <-Compute_Sample_Profitability(x)
  }

hist(df_test$Max_calls)
nrow(df_test[df_test$Max_calls<df_test$campaign])/nrow(df_test)

```

```{r}
#compute profit of calling all (as called)
baseline_profit <-0
for (x in 1:nrow(df_test)) {
  if(df_test$Class[x]=="FALSE") { baseline_profit<-baseline_profit-df_test$campaign[x]*fail_cost
                                } else { baseline_profit<-baseline_profit+Success_profit-(df_test$campaign[x]-1)*fail_cost}
  
}
baseline_profit
#compute profit of implementing strategy?
logit_profit <-0
for (x in 1:nrow(df_test)) {
  if  (df_test$campaign[x]>df_test$Max_calls[x]){
      -df_test$Max_calls[x]*fail_cost 
      } else {
                if(df_test$Class[x]=="FALSE"){ 
                  logit_profit<-logit_profit-df_test$campaign[x]*fail_cost
                  } else { logit_profit<-logit_profit+Success_profit-(df_test$campaign[x]-1)*fail_cost}
              }

}
#Gains
logit_profit/baseline_profit-1

three_call_profit <-0
for (x in 1:nrow(df_test)) {
  if  (df_test$campaign[x]>3){
      -3*fail_cost 
      } else {
                if(df_test$Class[x]=="FALSE"){ 
                  three_call_profit<-three_call_profit-df_test$campaign[x]*fail_cost
                  } else { three_call_profit<-three_call_profit+Success_profit-(df_test$campaign[x]-1)*fail_cost}
              }

}

two_call_profit <-0
for (x in 1:nrow(df_test)) {
  if  (df_test$campaign[x]>2){
      -2*fail_cost 
      } else {
                if(df_test$Class[x]=="FALSE"){ 
                  two_call_profit<-two_call_profit-df_test$campaign[x]*fail_cost
                  } else { two_call_profit<-two_call_profit+Success_profit-(df_test$campaign[x]-1)*fail_cost}
              }

}
two_call_profit
three_call_profit
logit_profit
baseline_profit
#alt model - make 3 calls to everyone


```


```{r}
### KNN - euclidean approach. when using full_df, there are no predicted conversions

# campaign dummies; age; retired; student. adjust to match other models
TrnX <- model_df[1:10000,c(15:18,2,8,11)]

OrigTrnGdf <- model_df[1:10000,1]
OrigTrnG <- OrigTrnGdf$Class

TstX <- model_df[10001:12000,c(15:18,2,8,11)]

nnresult <- data.frame("Neighbors" = NULL, "Total_Calls" = NULL, "Good_Calls" = NULL, "Total_Profit" = NULL)
for (i in 1:20){
  nn <- knn(TrnX, TstX, OrigTrnG, k=i, l = 0, prob=FALSE, use.all = FALSE)
  nn <- cbind(nn,knn_df[10001:12000,4])
  
  nn$call <- 0
  nn$call[nn$nn==TRUE] <- 1
  
  nn$match <- nn$nn == nn$Class & nn$Class== TRUE
  nn$profit <- 0
  nn$profit[nn$match==TRUE] <- Success_profit
  
  nn$failcall <- nn$nn == TRUE & nn$Class == FALSE
  nn$failcost <-0
  nn$failcost[nn$failcall==TRUE] <- fail_cost
  
  thisresult <- data.frame("Neighbors" = i ,
                           "Total_Calls" = sum(nn$call), 
                           "Good_Calls" = length(nn$match[nn$match==TRUE]),
                           "Total_Profit" = sum(nn$profit) - sum(nn$failcost)
                           )

  nnresult <- rbind(nnresult, thisresult)
}
nnresult

### KNN - euclidean approach using non-blown-out data
#age, retired, student
knn_df <- df[campaign <=5, ]
knn_df <- knn_df[1:12000,c(1,7,10,56)]

TrnX <- knn_df[1:10000,1:3]
OrigTrnG <- knn_df[1:10000]$Class

TstX <- knn_df[10001:12000,1:3]

nnresult <- data.frame("Neighbors" = NULL, "Total_Calls" = NULL, "Good_Calls" = NULL, "Total_Profit" = NULL)
for (i in 1:20){
  nn <- knn(TrnX, TstX, OrigTrnG, k=i, l = 0, prob=FALSE, use.all = FALSE)
  nn <- cbind(nn,knn_df[10001:12000,4])
  
  nn$call <- 0
  nn$call[nn$nn==TRUE] <- 1
  
  nn$match <- nn$nn == nn$Class & nn$Class== TRUE
  nn$profit <- 0
  nn$profit[nn$match==TRUE] <- Success_profit
  
  nn$failcall <- nn$nn == TRUE & nn$Class == FALSE
  nn$failcost <-0
  nn$failcost[nn$failcall==TRUE] <- fail_cost
  
  thisresult <- data.frame("Neighbors" = i ,
                           "Total_Calls" = sum(nn$call), 
                           "Good_Calls" = length(nn$match[nn$match==TRUE]),
                           "Total_Profit" = sum(nn$profit) - sum(nn$failcost)
                           )

  nnresult <- rbind(nnresult, thisresult)
}
nnresult

### KNN with Mahalanobis distances: computationally taxing; cannot compute enough to compare against model
## first Mahalanobis approach: knnGarden package
#install.packages("knnGarden")
library(knnGarden)
knnMCN(TrnX=TrnX[1:1000,],OrigTrnG=OrigTrnG[1:1000],TstX=TstX[1:200,],ShowObs=FALSE,K=1)

## second Mahalanobis approach: pvclass package. computationally taxing; subsetted to 1000 rows in dev 
library(pvclass)
knnout <- cvpvs.knn(TrnX[1:1000], OrigTrnG[1:1000], k = 1, distance = 'mahalanobis', cova = 'standard')
```



#Splitting
```{r}
```


## Regression Tree
```{r}
set.seed(99)
fit1 = rpart(lnSalePrice~., data=train, control=rpart.control(minsplit=5, cp=0.0001, xval=10))

nbig = length(unique(fit1$where))
cat('Size of big tree: ',nbig,'\n')

cat('RMSE=',sqrt(mean((test$lnSalePrice-predict(fit1,test))^2)),'\n')

(cptable = printcp(fit1))
(bestcp = cptable[ which.min(cptable[,"xerror"]), "CP" ])   
fit1B = prune(fit1,cp=bestcp)
nbigB = length(unique(fit1B$where))
cat('Size of pruned tree: ',nbigB,'\n')

cat('RMSE=',sqrt(mean((test$lnSalePrice-predict(fit1B,test))^2)),'\n')
```


## Random Forest
```{r tree all vars, echo=FALSE}
set.seed(99)
fit2 <- randomForest(lnSalePrice~., data=train, ntree=400)
cat('RMSE is ',sqrt(mean((test$lnSalePrice - (predict(fit2, test)))^2)),'\n')

```


## Boosting
```{r boosting}
set.seed(99)
# Inputs, Regression Setting
fboost <- gbm(lnSalePrice~.,           # regression model
           data=train,              # data set
           distribution="gaussian", # boost the squared error, "tdist", 'laplace'
           n.trees=500,             # Total number of trees/iterations
           interaction.depth = 1,   #1 means additive, 2 means 2-way interaction, etc
           shrinkage=0.02           # Shrinkage parameter, weak predictor
           )

# Returned Values, Returned predictor
# Making prediction
cat('RMSE is',sqrt(mean((test$lnSalePrice-predict(fboost,newdata=test,n.trees=500))^2)),'\n')
```






#--Simple Regression Stuff--
```{r}
# reg <- glm(outcome~.-duration, family="binomial", data=df_train)
# summary(reg)
```

# Basic prediction exercise 
High accuracy but mostly driven by high count of true falses
```{r}
# pred_test <- ifelse(predict(reg, df_test, type="response")>0.5,TRUE,FALSE)
# confusionMatrix(pred_test,df_test$Class)
```


# Simple target top 100
```{r}
# pred_test1 <- predict(reg, df_test, type="response")
# test1_index <- sort(pred_test1, index.return=TRUE, decreasing=TRUE)$ix[1:100]
# pred_test1tf <- ifelse(pred_test1[test1_index]>0.5,TRUE,FALSE)
# confusionMatrix(pred_test1tf,df_test$Class[test1_index])
```

# Can we pick those with greater than 50% odds of responding?
```{r}
# pred_test2 <- predict(reg, df_test, type="response")
# num_true_pred2 <- sum(sort(pred_test2, index.return=TRUE, decreasing=TRUE)$x>0.5)
# test2_index <- sort(pred_test2, index.return=TRUE, decreasing=TRUE)$ix[1:num_true_pred2]
# pred_test2tf <- ifelse(pred_test2[test2_index]>0.5,TRUE,FALSE)
# confusionMatrix(pred_test2tf,df_test$Class[test2_index])
```





